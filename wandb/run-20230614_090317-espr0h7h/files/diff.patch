diff --git a/requirements.txt b/requirements.txt
index ff9dbd1..94890cc 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -3,4 +3,7 @@ fastai
 numpy 
 pandas
 pydantic
+wandb
+prefect_aws
+prefect_gcp
 prefect==2.10.2
diff --git a/src/train_model.py b/src/train_model.py
index edb7da4..33ba81d 100644
--- a/src/train_model.py
+++ b/src/train_model.py
@@ -1,11 +1,16 @@
+import wandb
+
+from dotenv import load_dotenv
 from fastai.collab import *
 from fastai.tabular.all import *
+from fastai.callback.wandb import WandbCallback
 from prefect import flow, task
 from prefect_gcp import GcpCredentials
 from prefect.deployments import Deployment
 
 from config import Location
 
+load_dotenv()
 
 @task(log_prints=True)
 def get_data():
@@ -22,12 +27,14 @@ def get_data():
 
 @task(log_prints=True)
 def train_model(df: pd.DataFrame):
+    wandb.init()
+
     print("Starting training")
     df = df.loc[:, ["user", "movie", "rating"]]
     df = df.astype({"rating": "float"})
     dls = CollabDataLoaders.from_df(df, bs=8)
-    learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))
-    learn.fit_one_cycle(5, 5e-3, wd=0.1, cbs=[ShortEpochCallback()])
+    learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5), cbs=[ShortEpochCallback(), SaveModelCallback()])
+    learn.fit_one_cycle(2, 5e-3, wd=0.1)
 
     print("Finished training")
     return learn
@@ -47,11 +54,12 @@ def train(location: Location = Location()):
 
 
 if __name__ == "__main__":
-    deployment = Deployment.build_from_flow(
-        flow=train,
-        name="train-model",
-        infra_overrides={"env": {"PREFECT_LOGGING_LEVEL": "DEBUG"}},
-        work_queue_name="movielens",
-    )
-    deployment.apply()
+    train()
+    # deployment = Deployment.build_from_flow(
+    #     flow=train,
+    #     name="train-model",
+    #     infra_overrides={"env": {"PREFECT_LOGGING_LEVEL": "DEBUG"}},
+    #     work_queue_name="movielens",
+    # )
+    # deployment.apply()
     
\ No newline at end of file
